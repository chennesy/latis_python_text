{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "863162ad-6e1c-4fec-894c-5c4fbec036e3",
   "metadata": {},
   "source": [
    "# Text analysis with AI\n",
    "A workshop by UMN LATIS and the Libraries.\n",
    "\n",
    "## What we'll cover in this session\n",
    "- Understand text classification with LLMs, and how it can be useful for text-based research.\n",
    "- Interact with the ChatGPT API.\n",
    "- Structure API calls using different models and prompts\n",
    "- Set up classification tasks with ChatGPT.\n",
    "- Understand and parse API JSON responses.\n",
    "- Understand risks in using generative AI for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496bad16-9c12-47d1-90b8-26f29baecbc0",
   "metadata": {},
   "source": [
    "### Install libraries\n",
    "If you're working from your own machine you can use pip install to make sure you have downloaded all of the Python packages you'll need to use today. \n",
    "\n",
    "If you're working on notebooks.latis.umn.edu, there's no need to install any of these, since they're included in the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac31f92-047c-49bc-b862-7d57dca9e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install Libraries ###\n",
    "\n",
    "#!pip install --upgrade openai python-dotenv\n",
    "#!pip install spacy\n",
    "\n",
    "# This command downloads the medium-sized English language model for spaCy.\n",
    "# It uses the Python module-running option to run spaCy's download command for the \"en_core_web_md\" model.\n",
    "#!python -m spacy download en_core_web_md "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda311ed-7c9c-4c5a-be61-bd0c7ed10a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries ###\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be59a016-04f2-4beb-bb54-0b9dca5e0d06",
   "metadata": {},
   "source": [
    "# ChatGPT: website vs. API\n",
    "\n",
    "The [chat interface on the website](https://chatgpt.com) is the most familiar way of interacting with these models.\n",
    "\n",
    "But we will be working with the [application programming interface (API)](https://en.wikipedia.org/wiki/API) to automatically send and receive messages from the model using some features that are not accessible via the web.\n",
    "\n",
    "## OpenAI's API\n",
    "\n",
    "Many applications and websites offer APIs. For example, nearly every weather app uses [the National Weather Service API](https://www.weather.gov/documentation/services-web-api) to automatically retrieve weather data.\n",
    "\n",
    "Unlike the National Weather Service, OpenAI charges for the use of its API. Which means that calls to the API require a special string called a `key`.\n",
    "\n",
    "### Getting a key\n",
    "\n",
    "After installing the Python bindings above (`openai`), you need to get an API key to send requests. The key is a unique identifier that performs a number of functions (including allowing OpenAI to bill you).\n",
    "\n",
    "For the purposes of this class, I have created a fresh key with a spending limit of `$10` that I will share with the group, which should be more than enough to satisfy all of the requests in this class.\n",
    "\n",
    "When you want to run your own queries in the future, you will need to register for an account and create an API key.\n",
    "\n",
    "See [this page of the documentation](https://platform.openai.com/docs/quickstart) for details of how to create your own key.\n",
    "\n",
    "### Setting the key\n",
    "\n",
    "You need to include the key with every call to the API.\n",
    "\n",
    "One way to do this is by setting the `OPENAI_API_KEY=...` variable in a `.env` file in your working directory.\n",
    "\n",
    "You can also do this by setting a local variable, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d82ea-a822-46e4-9522-db60171ab8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"  # copy-paste the class key here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7636e15-9714-445c-972f-8c0f322113c0",
   "metadata": {},
   "source": [
    "We're also going to write this to your `.env` so you don't have to repeat the process next time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc80b4-87c2-4f23-9a23-f5a3f94a0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\".env\", \"w\") as f:\n",
    "    f.write(f\"OPENAI_API_KEY={OPENAI_API_KEY}\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f37ec4-1633-413b-9f82-1a02427d78c2",
   "metadata": {},
   "source": [
    "Next time your restart this notebook kernel (or open up a new notebook), the `openai` library will read the API key directly from your `.env` file. No need to specify the `api_key=` argument in `OpenAI()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a0293b-eeea-4d23-9abc-43e1c4f93196",
   "metadata": {},
   "source": [
    "## Making your first API call\n",
    "\n",
    "You installed and imported the `openai` library above, so now you can run the example completion below, which is part of [OpenAI's tutorial](https://platform.openai.com/docs/api-reference/chat/create):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e59d79-ed15-41c9-83bb-5554cd6074cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will load your saved .env variable\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0b0d8-3a66-4329-9613-324ea7d37210",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an academic researcher with machine learning expertise.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain what text classification is in ten or fewer words.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab471885-c5c4-4c1d-a362-6d5824c49f65",
   "metadata": {},
   "source": [
    "Let's breakdown the elements from the code above:\n",
    "- `client.chat.completions.create()` calls the REST API chat completions endpoint\n",
    "- `model=\"gpt-4o-mini\"` - you can choose from a variety of [ChatGPT models](https://platform.openai.com/docs/models). We're using a lightweight (affordable) `gpt-40-mini` model. To get slightly more intelligent responses you could switch to `gpt-40`.\n",
    "- `messages` is a list of dictionaries contains messages sent to the `model`.\n",
    "  - There are two different values given for `role` in this example: `system` and `user`.\n",
    "  - `system` refers to the system message given to the LLM that conditions its reponses.\n",
    "\n",
    "Note how the output below differs from the output above, only changing the `system` message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464742c-b0a4-4a11-8102-21022b93d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a French tutor. Respond to all prompts in French followed by English in parentheses.\"\n",
    "user_message = \"Explain what text classification is in ten or fewer words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6270e5-b7f8-46e1-a0d8-f97ae4e64744",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_message,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51902a0-e73a-4266-bb41-07b72043a7dc",
   "metadata": {},
   "source": [
    "You can explore the response by hitting tab after `completion.`. \n",
    "- `completion.usage` shows you how many tokens you sent and received. The number of tokens for each model corresponds to what you will be charged for your API usage. See [OpenAI's pricing page](https://openai.com/api/pricing/) for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a7176d-b680-4a67-8c89-baad6577e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921bf863-2b02-456b-af73-639de62cd570",
   "metadata": {},
   "source": [
    "- `completion.choices[0].` refers to the first response from the API. In our case we only have one response, but other queries can return a list of different API responses at different indices (e.g., `completion.choices[1]`).\n",
    "- `completion.choices[0].message.content` has the response content that we're interested in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3aeea-45a7-4dd2-9b24-bc589e595ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662f8ae0-d471-4b51-b3e7-0fa54d82edca",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Create a new system message and user message to send to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2aca7-fbcc-426c-9162-2a02c6fec730",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\n",
    "user_message = \"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    max_completion_tokens = 150, # this sets a maximum length of the response to keep our API costs down\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_message,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08934891-72ff-4d35-8790-3c58ddf8c09b",
   "metadata": {},
   "source": [
    "### Using LLMs for classification \n",
    "\n",
    "We can write a simple system prompt to ask to classify text into various categories. First let's create a function for our API call to make it easier to reuse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029da1a7-d583-434c-a844-dd8c8b4736a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_call(system_message, user_message):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        max_completion_tokens = 100,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_message,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_message,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    print(f\"Headline: {user_message} \\nClassification: {response}\")\n",
    "    print()\n",
    "    return user_message, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b4fd8-f2b3-418b-86c5-4d6533db54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"Classes: \n",
    "['U.S.', 'World', 'Business', 'Arts', 'Lifestyle', 'Opinion', 'Sports', 'Science', 'Other']\n",
    "Classify the user input (newspaper headlines) into one of the above classes. \n",
    "If the headlines doesn't match a category, respond 'Other'.\"\"\"\n",
    "\n",
    "user_message = \"After a decade, scientists unveil fly brain in stunning detail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80756b9a-5af7-46c2-aaa0-ccbd7b6bb16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message, response = api_call(system_message, user_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165d4782-a29a-42b6-9adb-a0d523ecdfac",
   "metadata": {},
   "source": [
    "#### Newspaper headlines\n",
    "Let's import a list of newspaper headlines from the US, [collected on Kaggle](https://www.kaggle.com/datasets/felixludos/babel-briefings).\n",
    "\n",
    "The dataset is in JSON format, so we'll import the JSON library to work with the data and load it in a similar way as text files. `json.load` converts the JSON data into a Python object we can work with as a list of dictionaries for each headline \"item\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22900130-d61e-45ef-8f3d-1fb5e330c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# US headlines from https://www.kaggle.com/datasets/felixludos/babel-briefings?resource=download\n",
    "\n",
    "with open('data/babel-briefings-v1-us.json') as json_data:\n",
    "    headlines = json.load(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57333d7-b545-453e-84f8-2de22eb0f37f",
   "metadata": {},
   "source": [
    "Let's take a look at the dictionary for a single item in the headlines list. We want to work with the 'title' for each item, which is accessible via the dictionary key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4ac8c-53e2-4094-bcc3-1b44981b5421",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f554b-be13-4910-a942-26effee9b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines[0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e944d55-faac-4aa9-b997-4e1eec489fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's print out classifications for the first ten items\n",
    "for headline in headlines[0:10]:\n",
    "    api_call(system_message, headline['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1071eb-6998-42fa-9adb-6262f861cc30",
   "metadata": {},
   "source": [
    "### Using LLMs for Named Entity Recognition (NER)\n",
    "We can use the same technique, with a different system prompt, to ask for named entities (people, places, and other formal nouns) from each headline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3aa787-b4e5-482f-a296-dea3f95c63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"For each user input (newspaper headlines), give me a list of:\n",
    "- organization named entity\n",
    "- location named entity\n",
    "- person named entity\n",
    "Format the output in valid json with the following keys:\n",
    "- Organizations\n",
    "- Locations\n",
    "- Persons\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0837c-843f-4e63-9581-4a7ad251798e",
   "metadata": {},
   "source": [
    "Instead of just printing our results, let's save them to a new Python dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4290b6-81c2-448a-8bf0-7cf74dfd2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_ner = {}\n",
    "for headline in headlines[20:30]:\n",
    "    headline, response = api_call(system_message, headline['title'])\n",
    "    headline_ner[headline] = response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b181a76e-511e-4f7d-8952-ec09d0756569",
   "metadata": {},
   "source": [
    "Some of the JSON is not valid, despite our prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c327342-ea97-42b4-a4e8-471d7afcd46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in headline_ner.items():\n",
    "    print(k)\n",
    "    print(json.loads(v))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac69f0-7c05-4899-8ec3-77e531ee3aee",
   "metadata": {},
   "source": [
    "### Exercise: Fix invalid JSON\n",
    "Some of the JSON that ChatGPT returned isn't valid! Can you edit the system prompt and re-run the API call to pull in valid JSON?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734a532-a90f-4f6e-8f07-a8b468bf2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"For each user input (newspaper headlines), give me a list of:\n",
    "- organization named entity\n",
    "- location named entity\n",
    "- person named entity\n",
    "Format the output in valid json with the following keys:\n",
    "- Organizations\n",
    "- Locations\n",
    "- Persons\n",
    "Do not include quotes or the term json in the response.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44114c60-b77a-4387-9578-e6da75b5357c",
   "metadata": {},
   "source": [
    "### Using LLMs for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3eb8ba-4154-4482-9ea2-fc1abc4d75fe",
   "metadata": {},
   "source": [
    "## spacy-llm wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34da41-b882-4feb-bb92-3a6f2628f6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
